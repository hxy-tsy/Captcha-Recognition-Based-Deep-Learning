# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'd:\code\python\Outsourcing\captcha\intorduce.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets


class Ui_introduce(object):
    # 定义常量
    CNN_INTRODUCTION = """
    CNN（卷积神经网络，Convolutional Neural Network）是一种深度学习模型，主要用于处理具有网格结构的数据，如图像、视频和音频。CNN 在计算机视觉领域表现尤为出色，广泛应用于图像分类、目标检测、图像分割等任务。
    CNN 的核心结构
    - 卷积层（Convolutional Layer）: 通过卷积核（滤波器）在输入数据上滑动，提取局部特征。卷积操作可以捕捉空间层次的特征，例如边缘、纹理等。多个卷积核可以提取不同的特征。
    - 激活函数（Activation Function）: 常用的激活函数包括 ReLU（Rectified Linear Unit）、Sigmoid 和 Tanh。ReLU 是最常用的激活函数，公式为 f(x)=max(0,x)，能够加速训练并缓解梯度消失问题。
    - 池化层（Pooling Layer）: 用于降维，减少计算量，同时增强模型的鲁棒性。常见的池化操作包括最大池化（Max Pooling）和平均池化（Average Pooling）。
    - 全连接层（Fully Connected Layer）: 将卷积层和池化层提取的特征进行整合，输出最终的分类或回归结果。通常位于网络的最后几层。
    - Dropout: 一种正则化技术，随机丢弃部分神经元，防止过拟合。
    - 批归一化（Batch Normalization）: 对每一层的输入进行归一化，加速训练并提高模型稳定性。
    CNN 的优势
    - 局部感知：卷积核只关注局部区域，减少了参数量。
    - 参数共享：卷积核在输入数据上共享参数，进一步降低计算复杂度。
    - 平移不变性：卷积操作对输入数据的平移具有鲁棒性。
    """
    GRU_INTRODUCTION = """
    GRU（门控循环单元，Gated Recurrent Unit）是一种改进的循环神经网络（RNN）结构，由 Cho 等人在 2014 年提出。GRU 旨在解决传统 RNN 的梯度消失问题，同时比 LSTM（长短期记忆网络）更简单高效。GRU 通过引入门控机制，能够更好地捕捉时间序列数据中的长期依赖关系。
    ### GRU 的核心结构
    GRU 的核心是两个门控机制：更新门（Update Gate）和重置门（Reset Gate）。这些门控机制决定了信息的流动方式。
    #### 更新门（Update Gate）
    控制当前状态中有多少信息来自前一时刻的状态。
    公式：z_t = sigma(W_z *[h_{t-1}, x_t])
    其中，
    - z_t是更新门的输出，
    - sigma是 Sigmoid 函数，
    - h_{t-1}是前一时刻的隐藏状态，
    - x_t是当前输入。
    #### 重置门（Reset Gate）
    控制前一时刻的隐藏状态对当前候选状态的影响。
    公式：r_t = sigma(W_r*[h_{t-1}, x_t]) 
    其中，
    - r_t是重置门的输出。
    #### 候选隐藏状态（Candidate Hidden State）
    结合当前输入和重置门的结果，生成候选状态。
    公式：{h}_t = tanh(W * r_t * h_{t-1}, x_t]) 
    其中，
    - {h}_t是候选状态，
    - *表示逐元素相乘。
    #### 最终隐藏状态（Final Hidden State）
    结合更新门和候选状态，生成当前时刻的隐藏状态。
    公式：h_t = (1 - z_t)*h_{t-1} + z_t*{h}_t
    ### GRU 的工作流程
    1. 输入时间序列数据x_t和前一时刻的隐藏状态h_{t-1}。
    2. 计算更新门z_t和重置门r_t。
    3. 生成候选隐藏状态{h}_t。
    4. 结合更新门和候选状态，输出当前时刻的隐藏状态h_t。
    ### GRU 的优势
    - 简化结构：相比 LSTM，GRU 只有两个门（更新门和重置门），参数量更少，计算效率更高。
    - 缓解梯度消失：通过门控机制，GRU 能够更好地捕捉长期依赖关系。
    - 适合短序列任务：在短序列任务中，GRU 的性能通常与 LSTM 相当，甚至更好。
    """

    RESIDUAL_BLOCK_INTRODUCTION = """
    随着网络深度的增加，网络能获取的信息量随之增加，而且提取的特征更加丰富。然而在残差结构提出之前，实验证明，随着网络层数的增加，模型的准确率起初会不断提高，直至达到最大饱和值。然后，随着网络深度进一步增加，模型的准确率不再增加，反而可能出现明显的降低，这被称为“退化问题”。该问题的发生主要是由于深度神经网络训练中的梯度消失和梯度爆炸问题。
    在传统的深度神经网络中，随着网络层数的增加，反向传播的梯度会逐渐减小或增大，导致网络难以收敛或变得不稳定。该现象的一种解释是，当网络变得非常深时，低层参数的微小变动会引起高层参数的剧烈变化，使得优化算法难以找到最优解。何恺明等人于 2015 年提出的残差网络 ResNet 旨在解决这一问题。通过引入残差模块，残差网络允许梯度通过跳过一定数量的层来传播，使得即便是很深的网络也能更容易地进行训练。
    假设网络的输入是x，期望输出为H(x)我们转化一下思路，把网络要学到的H(x)转化为期望输出H(x)与输入x之间的差值F(x) = H(x) - x。当残差接近为 0 时，相当于网络在此层仅仅做了恒等变换，而不会使网络的效果下降。
    残差模块如图所示，X_l在残差学习模块中充当输入，同时通过跳跃连接传递到输出。假设两个卷积层学习到的信息增量为F(X_l)，则最终残差学习模块的输出为F(X_l) + X_l。残差模块专注于学习残差信息F(X_l)，即模块输出相比输入的信息增量。其核心思想可表示为：
     X_{l+1} = X_l + F(X_l). 
    """

    YOLOV11_INTRODUCTION = """
    YOLOv11 是 Ultralytics YOLO 系列的最新版本，基于之前 YOLO 版本的成功，引入了新特性和改进，进一步提升性能和灵活性。以下是对 YOLOv11 的详细介绍：
    ### 一、主要特点
    - **增强的特征提取**：YOLOv11 使用改进的主干和颈部架构来增强特征提取，以实现更精确的目标检测和复杂任务的性能。这可能涉及到更高效的卷积操作、注意力机制或其他先进的神经网络架构组件。
    - **针对效率和速度优化**：精细的架构设计和优化的训练流程在保持准确性和性能之间最佳平衡的同时，提供更快的处理速度。
    - **更少的参数，更高的准确度**：与 YOLOv8 相比，YOLOv11 具有更少的参数和更好的结果。例如，YOLOv11m 在 COCO 数据集上实现了比 YOLOv8m 更高的 mAP（平均精度均值），参数减少了 22%，提高了计算效率，同时不牺牲准确度。
    - **跨环境的适应性**：YOLOv11 可以无缝部署在边缘设备、云平台和配备 NVIDIA GPU 的系统上，确保最大的灵活性。
    - **支持广泛的任务范围**：YOLOv11 支持各种计算机视觉任务，如目标检测、实例分割、图像分类、姿态估计和定向目标检测（OBB）等。
    ### 二、技术改进
    - **Backbone**：使用了 C2K2 模块，并在最后 SPPF 模块级联 C2PSA 模块。
    - **Neck**：使用 PAN 结构，并且里面也使用 C3K2 模块。
    - **Head**：使用了 anchor-free+Decoupled-head，其中回归头使用正常的卷积，分类头使用 DWConv（深度可分离卷积）。
    - **损失函数**：使用了分类 BCE（二元交叉熵）、回归 CIOU+VFL（Variance Focal Loss，方差焦点损失）的组合。
    - **框匹配策略**：由静态匹配改为了 Task-Aligned Assigner 匹配方式。
    ### 三、应用场景
    由于 YOLOv11 具有高效、准确和灵活的特点，它适用于各种计算机视觉任务，包括但不限于自动驾驶、安防监控、机器人视觉、医疗影像分析等领域。在这些领域中，YOLOv11 能够帮助实现实时的目标检测、跟踪和分类等功能，从而提高系统的性能和可靠性。
    ### 四、总结
    YOLOv11 作为 Ultralytics YOLO 系列的最新版本，在目标检测领域具有显著的优势。它通过改进的特征提取机制、优化的模型架构和端到端效率提升等技术手段，实现了更高的准确度和更快的处理速度。同时，YOLOv11 还支持广泛的任务范围并具有良好的跨环境适应性，使得它能够在各种应用场景中发挥出色的性能。
    """

    UNET_INTRODUCTION = """
    UNet 是一种常用于医学影像分割任务的深度学习架构，由 Olaf Ronneberger、Philipp Fischer 和 Thomas Brox 在 2015 年提出。UNet 架构的设计灵感来源于全卷积网络（FCN），但它在多个方面进行了改进，以更好地适应医学影像分割的需求。
    ### 一、架构特点
    - **对称的 U 型结构**：UNet 架构呈现出一个 U 型的对称结构，包括一个收缩路径（下采样路径）和一个扩展路径（上采样路径）。收缩路径用于捕获上下文信息，而扩展路径则用于精确定位分割边界。
    - **跳跃连接**：在收缩路径和扩展路径之间，UNet 采用了跳跃连接，这些连接将特征从收缩路径直接传递到扩展路径的相应层级。这种设计有助于保留高分辨率特征，从而改善分割结果的边界细节。
    - **卷积操作**：UNet 中的卷积操作通常使用有效的 3x3 卷积，以确保计算效率和特征学习能力。在每个卷积层之后，通常会应用 ReLU 激活函数和批量归一化（Batch Normalization）来加速训练过程并提高模型性能。
    - **上采样操作**：在扩展路径中，UNet 使用上采样操作（如双线性插值或转置卷积）来恢复特征图的分辨率。上采样后的特征图与收缩路径中通过跳跃连接传递的特征图进行拼接，以实现特征的融合。
    ### 二、应用场景
    由于 UNet 架构在医学影像分割任务中表现出色，它已被广泛应用于各种医学影像分析领域，包括但不限于：
    - **细胞分割**：在显微镜图像中自动识别和分割细胞，以支持病理学研究。
    - **器官分割**：在 CT 或 MRI 图像中自动分割人体器官，以辅助手术规划、疾病诊断和治疗评估。
    - **血管分割**：在医学影像中分割血管结构，以支持血管疾病的研究和治疗。
    - **病变检测与分割**：在医学影像中检测和分割病变区域，如肿瘤、囊肿等，以辅助疾病的早期发现和诊断。
    ### 三、改进与变体
    随着深度学习技术的不断发展，UNet 架构也经历了多种改进和变体，以适应不同的应用场景和需求。例如：
    - **3D UNet**：将 2D UNet 扩展到 3D，以处理体积数据（如 CT 或 MRI 扫描），从而支持三维医学影像分割。
    - **ResUNet**：在 UNet 中引入残差连接（Residual Connections），以提高模型的深度和特征学习能力。
    - **Attention UNet**：在 UNet 中引入注意力机制，以增强模型对关键特征的关注度，从而提高分割性能。
    - **UNet++**：通过引入嵌套和密集跳跃连接来改进 UNet 架构，以提高分割结果的准确性和鲁棒性。
    总之，UNet 作为一种高效且灵活的医学影像分割架构，在医学影像分析领域发挥着重要作用。随着技术的不断进步和应用场景的拓展，UNet 及其变体将继续在医学影像分割领域发挥更大的作用。
    """

    # 设置文本
    def load_introduce(self):
        if self.comboBox.currentText() == "CNN(卷积神经网络)":
            self.plainTextEdit.setPlainText(self.CNN_INTRODUCTION)
        elif self.comboBox.currentText() == "YOLOV11":
            self.plainTextEdit.setPlainText(self.YOLOV11_INTRODUCTION)
        elif self.comboBox.currentText() == "UNet":
            self.plainTextEdit.setPlainText(self.UNET_INTRODUCTION)
        elif self.comboBox.currentText() == "GRU(门控循环神经网络)":
            self.plainTextEdit.setPlainText(self.GRU_INTRODUCTION)
        elif self.comboBox.currentText()=="Residual BLock(残差块)":
            self.plainTextEdit.setPlainText(self.RESIDUAL_BLOCK_INTRODUCTION)

    def setupUi(self, Form):
        Form.setObjectName("介绍")
        Form.resize(847, 527)
        self.comboBox = QtWidgets.QComboBox(Form)
        self.comboBox.setGeometry(QtCore.QRect(230, 20, 341, 31))
        self.comboBox.setStyleSheet("font: 16pt \"Adobe 黑体 Std R\";")
        self.comboBox.setObjectName("comboBox")
        self.comboBox.currentIndexChanged.connect(self.load_introduce)
        self.comboBox.addItem("")
        self.comboBox.addItem("")
        self.comboBox.addItem("")
        self.comboBox.addItem("")
        self.comboBox.addItem("")
        self.plainTextEdit = QtWidgets.QPlainTextEdit(Form)
        self.plainTextEdit.setGeometry(QtCore.QRect(100, 70, 621, 411))
        self.plainTextEdit.setObjectName("plainTextEdit")
        self.plainTextEdit.setStyleSheet("font: 16pt \"Adobe 黑体 Std R\";")
        self.plainTextEdit.setReadOnly(True)
        self.pushButton = QtWidgets.QPushButton(Form)
        self.pushButton.setGeometry(QtCore.QRect(360, 490, 91, 31))
        self.pushButton.setObjectName("pushButton")

        self.retranslateUi(Form)
        QtCore.QMetaObject.connectSlotsByName(Form)

    def retranslateUi(self, Form):
        _translate = QtCore.QCoreApplication.translate
        Form.setWindowTitle(_translate("Form", "Form"))
        self.comboBox.setItemText(0, _translate("Form", "CNN(卷积神经网络)"))
        self.comboBox.setItemText(1, _translate("Form", "GRU(门控循环神经网络)"))
        self.comboBox.setItemText(2, _translate("Form", "Residual BLock(残差块)"))
        self.comboBox.setItemText(3, _translate("Form", "YOLOV11"))
        self.comboBox.setItemText(4, _translate("Form", "UNet"))
        self.pushButton.setText(_translate("Form", "返回"))
        self.plainTextEdit.setPlainText(_translate("Form", self.CNN_INTRODUCTION))

